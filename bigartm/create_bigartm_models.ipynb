{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T23:33:12.035146Z",
     "start_time": "2019-02-13T23:33:12.028748Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "sys.path.append('/home/midzay/Mlerning/bigartm/python')\n",
    "import artm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime as time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Internet_i_SMI.csv.bz2', 'Biznes.csv.bz2', 'Sport.csv.bz2']\n"
     ]
    }
   ],
   "source": [
    "PATH = 'data/all/' # Путь  к объединенным и обработанным датасетам \n",
    "PATH_BIGARTM_MODEL='data/model/bigartm/'\n",
    "\n",
    "files = list(os.walk(PATH))[0][2]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_topics = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T23:56:07.832847Z",
     "start_time": "2019-02-13T23:55:57.603888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель для Internet_i_SMI.csv.bz2\n",
      "\tSparsityThetaScore: 0.5631956458091736\n",
      "\tSparsityPhiScore: 0.8461095690727234\n",
      "\tPerplexityScore: 646.8890380859375\n",
      "Модель для Biznes.csv.bz2\n",
      "\tSparsityThetaScore: 0.5861086249351501\n",
      "\tSparsityPhiScore: 0.8355470299720764\n",
      "\tPerplexityScore: 252.99160766601562\n",
      "Модель для Sport.csv.bz2\n",
      "\tSparsityThetaScore: 0.6888564825057983\n",
      "\tSparsityPhiScore: 0.8592645525932312\n",
      "\tPerplexityScore: 328.2021179199219\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for file in files:\n",
    "    # загружаем и каждый предобработанный!!!!  датасет из PATH \n",
    "    df = pd.read_csv(PATH+file)\n",
    "    df = df[df.text!='text']\n",
    "    df.lemmatized_text = df.lemmatized_text.apply(lambda x: literal_eval(x))\n",
    "    df['year'] = df['date'].apply(lambda x: int(x.split(' ')[0].split('-')[0]))\n",
    "    df['month'] = df['date'].apply(lambda x: int(x.split(' ')[0].split('-')[1]))\n",
    "    df = df[df.year>2007]\n",
    "    df['docID'] = list(range(df.shape[0]))\n",
    "    df = df[['docID','year','month','lemmatized_text','text']]\n",
    "    df_data = df[['year','month']]\n",
    "    \n",
    "    # Приводим к формату  vowpal_wabbit\n",
    "    vwpath= f'data/vwpath/{file}_input_bigartm.vw'\n",
    "    with open(vwpath, 'w') as fp:\n",
    "        for text, did in df[['lemmatized_text', 'docID']].values:\n",
    "            fp.write('{} | {}\\n'.format(did, ' '.join(text)))\n",
    "    \n",
    "    # Создаем batches \n",
    "    batches_path = f'data/batches/{file}'\n",
    "    if not os.path.exists(batches_path):\n",
    "      \n",
    "        os.makedirs(batches_path)\n",
    "    \n",
    "    batch_vectorizer = artm.BatchVectorizer(data_path=vwpath,data_format='vowpal_wabbit',target_folder=batches_path)\n",
    "    \n",
    "    # Создаем словарь\n",
    "    dictionary = artm.Dictionary()\n",
    "    dictionary.gather(data_path=batches_path)\n",
    "    dictionary.filter(min_tf=10, max_df_rate=0.1)\n",
    "    \n",
    "    #Создаем модель\n",
    "    model = artm.ARTM(num_topics=select_topics, dictionary=dictionary, show_progress_bars=False)\n",
    "    \n",
    "\n",
    "    # scores\n",
    "    model.scores.add(artm.PerplexityScore(name='PerplexityScore', dictionary=dictionary))\n",
    "    model.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore'))\n",
    "    model.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore'))\n",
    "\n",
    "    # 1st regularizer\n",
    "    model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-1.0)) #-0.1\n",
    "    model.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=5)\n",
    "\n",
    "    # 2st regularizer\n",
    "    model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='SparseTheta', tau=-0.5))\n",
    "    model.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=15)\n",
    "\n",
    "    # 3st regularizer\n",
    "    model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='DecorrelatorPhi', tau=1.5e+5))\n",
    "\n",
    "    model.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=15)\n",
    "    \n",
    "    print (f'Модель для {file}')\n",
    "    print(f\"\\tSparsityThetaScore: {model.score_tracker['SparsityThetaScore'].last_value}\")\n",
    "    print(f\"\\tSparsityPhiScore: {model.score_tracker['SparsityPhiScore'].last_value}\")\n",
    "    print(f\"\\tPerplexityScore: {model.score_tracker['PerplexityScore'].last_value}\")\n",
    "    \n",
    "    # Сохраняем модель в каталог  PATH_BIGARTM_MODEL \n",
    "    file_mod = os.path.splitext(os.path.splitext(file)[0])[0]          \n",
    "    model.dump_artm_model(PATH_BIGARTM_MODEL+file_mod)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=artm.load_artm_model('/home/midzay/Mlerning/GitHUb/topic_news/bigartm/data/model/bigartm/Internet_i_SMI/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0: ['google' 'приложение' 'яндекс' 'мобильный' 'устройство' 'apple' 'запрос'\n",
      " 'поисковый' 'microsoft' 'поисковик' 'поиск' 'позволять' 'yahoo'\n",
      " 'компьютер' 'помощь']\n",
      "topic_1: ['холдинг' 'иск' 'эхо' 'радиостанция' 'редактор' 'гендиректор' 'акция'\n",
      " 'генеральный' 'должность' 'медиа' 'пост' 'дом' 'акционер' 'коммерсант'\n",
      " 'совет']\n",
      "topic_2: ['британский' 'news' 'великобритания' 'бибись' 'bbc' 'daily' 'житель'\n",
      " 'ребёнок' 'лондон' 'корпорация' 'guardian' 'world' 'фунт' 'возраст'\n",
      " 'таблоид']\n",
      "topic_3: ['реклама' 'миллиард' 'доллар' 'рынок' 'рубль' 'составить' 'рекламный'\n",
      " 'доля' 'продажа' 'аудитория' 'составлять' 'стоимость' 'месяц' 'рост'\n",
      " 'доход']\n",
      "topic_4: ['роскомнадзор' 'запретить' 'блокировка' 'ведомство' 'требование'\n",
      " 'telegram' 'законопроект' 'нарушение' 'госдума' 'реестр' 'заблокировать'\n",
      " 'законодательство' 'документ' 'мессенджер' 'депутат']\n",
      "topic_5: ['украина' 'украинский' 'корреспондент' 'задержать' 'убийство' 'произойти'\n",
      " 'журналистка' 'нападение' 'акция' 'здание' 'киев' 'смерть' 'протест'\n",
      " 'полицейский' 'республика']\n",
      "topic_6: ['ролик' 'фильм' 'реклама' 'youtube' 'видео' 'рекламный' 'игра' 'сериал'\n",
      " 'просмотр' 'шоу' 'кампания' 'трансляция' 'зритель' 'показать' 'актёр']\n",
      "topic_7: ['атака' 'хакер' 'безопасность' 'взлом' 'хакерский' 'документ' 'wikileaks'\n",
      " 'спецслужба' 'против' 'взломать' 'государство' 'правительство'\n",
      " 'публикация' 'расследование' 'национальный']\n",
      "topic_8: ['оператор' 'дождь' 'правительство' 'совет' 'развитие' 'министр' 'встреча'\n",
      " 'предложение' 'путин' 'проблема' 'предложить' 'минкомсвязи' 'абонент'\n",
      " 'государство' 'владимир_путин']\n",
      "topic_9: ['фотография' 'девушка' 'внимание' 'женщина' 'снимка' 'блогер' 'мужчина'\n",
      " 'комментарий' 'ребёнок' 'фото' 'написать' 'пост' 'обратить' 'очень'\n",
      " 'автор']\n",
      "topic_10: ['эфир' 'передача' 'ведущий' 'телевидение' 'вещание' 'нтв' 'тв' 'первое'\n",
      " 'домен' 'радио' 'телекомпания' 'радиостанция' 'вгтрк' 'вести' 'выпуск']\n",
      "topic_11: ['аккаунт' 'вконтакте' 'запись' 'блог' 'микроблог' 'популярный' 'друг'\n",
      " 'фотография' 'instagram' 'администрация' 'запустить' 'доступный'\n",
      " 'комментарий' 'пост' 'сообщество']\n",
      "topic_12: ['журнал' 'рейтинг' 'премия' 'редактор' 'конкурс' 'хороший'\n",
      " 'информационный' 'русский' 'редакция' 'номинация' 'риа' 'занять'\n",
      " 'печатный' 'версия' 'список']\n",
      "topic_13: ['new' 'times' 'книга' 'кандидат' 'выбор' 'обама' 'партия' 'номер'\n",
      " 'основатель' 'post' 'автор' 'университет' 'бывший' 'новое' 'журнал']\n",
      "topic_14: ['статья' 'уголовный' 'прокуратура' 'публикация' 'адвокат' 'обвинение'\n",
      " 'признать' 'орган' 'возбудить' 'преступление' 'рубль' 'расследование'\n",
      " 'факт' 'правоохранительный' 'экстремистский']\n"
     ]
    }
   ],
   "source": [
    "phi = model.get_phi()\n",
    "phi['word'] = phi.index\n",
    "phi['word']=phi.word.apply(lambda x: x[1])\n",
    "\n",
    "for col in phi.columns:\n",
    "    if col != 'word':\n",
    "        print(f\"{col}: {phi[[col, 'word']].sort_values(by=col, ascending=False)['word'].values[:15]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Текст из рубрики  интернет и сми\n",
    "text =['москва', 'отель', 'аэростарый', 'открыться', 'московский', 'международный', 'выставка',\n",
    "       'шоу', 'посвятить', 'новый', 'достижение', 'область', \n",
    "       'технология', 'выставка', 'продемонстрировать', 'последний', 'разработка',\n",
    "       'существующий', 'рынок',  'оборудование', 'программный', 'обеспечение', 'выставка', 'продлиться']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приводим к формату  vowpal_wabbit\n",
    "vwpath= f'data/vwpath/999_input_bigartm.vw'\n",
    "with open(vwpath, 'w') as fp:\n",
    "    fp.write('| {}\\n'.format(' '.join(text)))\n",
    "    \n",
    "    # Создаем batches \n",
    "batches_path = f'data/batches/999'\n",
    "if not os.path.exists(batches_path):\n",
    "    os.makedirs(batches_path)\n",
    "    \n",
    "bv = artm.BatchVectorizer(data_path=vwpath,data_format='vowpal_wabbit',target_folder=batches_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>topic_11</th>\n",
       "      <th>topic_12</th>\n",
       "      <th>topic_13</th>\n",
       "      <th>topic_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.106827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.334215</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic_0  topic_1  topic_2   topic_3  topic_4  topic_5   topic_6  topic_7  \\\n",
       "0  0.106827      0.0      0.0  0.119627      0.0      0.0  0.068265      0.0   \n",
       "\n",
       "    topic_8  topic_9  topic_10  topic_11  topic_12  topic_13  topic_14  \n",
       "0  0.371066      0.0       0.0       0.0       0.0  0.334215       0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = model.transform(batch_vectorizer=bv)\n",
    "theta.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
